<!DOCTYPE html>
<html lang="zh-cn"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    
    
    <title>基于 LLaMA 和 LangChain 实践本地 AI 知识库 - 元视角</title>
    <meta name="description" content="本文讨论了人工智能领域的最新发展，主要围绕着基于 Transformer 和 MoE 架构的多模态模型 Gemini 1.5 Pro，以及 OpenAI 推出的支持从文字生成视频的模型 Sora。文章提到通用人工智能（AGI）的实现正在加速，指出 AI 应用落地的主要实践围绕大模型微调、提示词工程和知识增强展开。在介绍 LangChain 中的知识库构建过程中，涉及Loader、Splitter、Embeddings 和 VectorStore 等步骤。此外，还讨论了 RAG 和 GPTs 在实践中的应用，以及LangChain 中的 Chain 概念，以及如何将其与大语言模型和知识库结合以实现 Q&amp;A 和 对话式检索。文章最后呼吁关注LangChain 的最新发展和替代品 AutoChain、Embedchain。">
    
    
    <link rel="shortcut icon" href="" type="image/x-icon">

    
    <link rel="icon" type="image/x-icon" href="/images/favicon.ico">

    
    <link rel="icon" type="image/png" href="/images/favicon.png">
    
    
    <meta property="og:title" content="基于 LLaMA 和 LangChain 实践本地 AI 知识库">
    <meta property="og:description" content="本文讨论了人工智能领域的最新发展，主要围绕着基于 Transformer 和 MoE 架构的多模态模型 Gemini 1.5 Pro，以及 OpenAI 推出的支持从文字生成视频的模型 Sora。文章提到通用人工智能（AGI）的实现正在加速，指出 AI 应用落地的主要实践围绕大模型微调、提示词工程和知识增强展开。在介绍 LangChain 中的知识库构建过程中，涉及Loader、Splitter、Embeddings 和 VectorStore 等步骤。此外，还讨论了 RAG 和 GPTs 在实践中的应用，以及LangChain 中的 Chain 概念，以及如何将其与大语言模型和知识库结合以实现 Q&amp;A 和 对话式检索。文章最后呼吁关注LangChain 的最新发展和替代品 AutoChain、Embedchain。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="http://localhost:1313/posts/practice-local-ai-knowledg-base-based-on-llama-and-langchain/">
    
    
    <link rel="stylesheet" href="/css/style.css">
    
    
    <link rel="stylesheet" href="/scss/main.min.b1a05553ee163b3165ac10f1ecfc75aefa2e2edd7b44e2eaf78764ff475e9523.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_3159629_2j0vwz8wd1k.css">
    
    
    <script src="/js/banner.js" defer></script>
    
    
    
    

    <link crossorigin="" rel="preconnect" href="https://s1.hdslb.com">
    <link crossorigin="" rel="preconnect" href="https://mirrors.sustech.edu.cn">
    <link crossorigin="anonymous" rel="stylesheet" href="https://s1.hdslb.com/bfs/static/jinkela/long/font/regular.css">
    <link crossorigin="anonymous" rel="stylesheet" href="https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/lxgw-wenkai-screen-webfont/1.7.0/style.css">
    <link crossorigin="anonymous" rel="stylesheet" href="https://cdn2.codesign.qq.com/icons/g5ZpEgx3z4VO6j2/latest/iconfont.css">
    <link rel="preconnect" href="https://use.sevencdn.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <link crossorigin="anonymous" href="https://use.sevencdn.com/css2?family=Fira+Code:wght@300..700&amp;display=swap" rel="stylesheet">
    <link href="https://X5EBEZB53I-dsn.algolia.net" rel="preconnect" crossorigin="">
</head> <body><div class="background patterns">
    
    <div class="bg-mask"></div>
    
    
    <div class="bg-image" style="background-image: url('https://tuapi.eees.cc/api.php?category=%7bdongman,fengjing%7d&amp;type=302')"></div>
    
    
    
</div> 

<style>
    .background {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: -2;
      &.patterns {
        background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='192' height='192' viewBox='0 0 192 192'%3E%3Cpath fill='%23494849' fill-opacity='0.08' d='M192 15v2a11 11 0 0 0-11 11c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H145v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11 13 13 0 1 1 .02 26 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43a6.1 6.1 0 0 0-3.03 4.87V143h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 181 164a11 11 0 0 0 11 11v2a13 13 0 0 1-13-13 12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84a6.1 6.1 0 0 0-4.87-3.03H145v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 124 181a11 11 0 0 0-11 11h-2a13 13 0 0 1 13-13c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43a6.1 6.1 0 0 0 3.03-4.87V145h-35.02a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 107 124a11 11 0 0 0-22 0c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H49v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11A13 13 0 0 1 81 192h-2a11 11 0 0 0-11-11c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V145H11.98a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 0 1 0 177v-2a11 11 0 0 0 11-11c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H47v-35.02a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 28 109a13 13 0 1 1 0-26c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43A6.1 6.1 0 0 0 47 84.02V49H11.98a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 11 28 11 11 0 0 0 0 17v-2a13 13 0 0 1 13 13c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84A6.1 6.1 0 0 0 11.98 47H47V11.98a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 68 11 11 11 0 0 0 79 0h2a13 13 0 0 1-13 13 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43A6.1 6.1 0 0 0 49 11.98V47h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 85 68a11 11 0 0 0 22 0c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H143V11.98a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 124 13a13 13 0 0 1-13-13h2a11 11 0 0 0 11 11c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V47h35.02a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 179 28a13 13 0 0 1 13-13zM84.02 143a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 83 124a13 13 0 1 1 26 0c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84a6.1 6.1 0 0 0 4.87 3.03H143v-35.02a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 164 107a11 11 0 0 0 0-22c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V49h-35.02a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 1 1 83 68a12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84A6.1 6.1 0 0 0 84.02 49H49v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 28 85a11 11 0 0 0 0 22c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V143h35.02z'%3E%3C/path%3E%3C/svg%3E");
      }
      &.dark {
        &.patterns {
          background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='192' height='192' viewBox='0 0 192 192'%3E%3Cpath fill='%23fcfcfc' fill-opacity='0.08' d='M192 15v2a11 11 0 0 0-11 11c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H145v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11 13 13 0 1 1 .02 26 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43a6.1 6.1 0 0 0-3.03 4.87V143h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 181 164a11 11 0 0 0 11 11v2a13 13 0 0 1-13-13 12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84a6.1 6.1 0 0 0-4.87-3.03H145v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 124 181a11 11 0 0 0-11 11h-2a13 13 0 0 1 13-13c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43a6.1 6.1 0 0 0 3.03-4.87V145h-35.02a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 107 124a11 11 0 0 0-22 0c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H49v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11A13 13 0 0 1 81 192h-2a11 11 0 0 0-11-11c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V145H11.98a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 0 1 0 177v-2a11 11 0 0 0 11-11c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H47v-35.02a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 28 109a13 13 0 1 1 0-26c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43A6.1 6.1 0 0 0 47 84.02V49H11.98a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 11 28 11 11 0 0 0 0 17v-2a13 13 0 0 1 13 13c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84A6.1 6.1 0 0 0 11.98 47H47V11.98a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 68 11 11 11 0 0 0 79 0h2a13 13 0 0 1-13 13 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43A6.1 6.1 0 0 0 49 11.98V47h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 85 68a11 11 0 0 0 22 0c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H143V11.98a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 124 13a13 13 0 0 1-13-13h2a11 11 0 0 0 11 11c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V47h35.02a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 179 28a13 13 0 0 1 13-13zM84.02 143a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 83 124a13 13 0 1 1 26 0c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84a6.1 6.1 0 0 0 4.87 3.03H143v-35.02a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 164 107a11 11 0 0 0 0-22c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V49h-35.02a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 1 1 83 68a12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84A6.1 6.1 0 0 0 84.02 49H49v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 28 85a11 11 0 0 0 0 22c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V143h35.02z'%3E%3C/path%3E%3C/svg%3E");
        }
        .cover {
          filter: brightness(0.6);
        }
      }
      .cover {
        width: auto;
        height: auto;
        min-height: 100%;
        opacity: 0;
        transition:
          filter 0.3s,
          opacity 0.3s;
        &.loaded {
          opacity: 1;
        }
      }
    }
    </style>
    
        <header class="main-header">
            <nav class="main-nav up top">
                <div class="nav-all">
                    
                     
                    <div class="left-nav">
                        
                        <div class="site-name" onclick="location.href='/'">
                            元视角
                        </div>
                    </div>
                    
                    
                    
                    <div class="nav-center">
                        <div class="site-menu"><div class="site-menu">
    
    <div class="menu-item">
        <span class="link-btn">文库</span>
        
        <div class="link-child">
            
            <span class="link-child-btn" onclick="window.location.href='\/'">
                
                <i class="iconfont icon-home"></i>
                
                文章列表
            </span>
            
            <span class="link-child-btn" onclick="window.location.href='\/categories'">
                
                <i class="iconfont icon-folder"></i>
                
                全部分类
            </span>
            
            <span class="link-child-btn" onclick="window.location.href='\/tags'">
                
                <i class="iconfont icon-hashtag"></i>
                
                全部标签
            </span>
            
        </div>
        
    </div>
    
    <div class="menu-item">
        <span class="link-btn">书影音</span>
        
        <div class="link-child">
            
            <span class="link-child-btn" onclick="window.location.href='\/reading'">
                
                <i class="iconfont icon-books"></i>
                
                读书
            </span>
            
            <span class="link-child-btn" onclick="window.location.href='\/watching'">
                
                <i class="iconfont icon-tv"></i>
                
                观影
            </span>
            
            <span class="link-child-btn" onclick="window.location.href='\/listening'">
                
                <i class="iconfont icon-music"></i>
                
                听歌
            </span>
            
        </div>
        
    </div>
    
    <div class="menu-item">
        <span class="link-btn">友链</span>
        
        <div class="link-child">
            
            <span class="link-child-btn" onclick="window.location.href='\/friends'">
                
                <i class="iconfont icon-people"></i>
                
                友情链接
            </span>
            
        </div>
        
    </div>
    
    <div class="menu-item">
        <span class="link-btn">关于</span>
        
        <div class="link-child">
            
            <span class="link-child-btn" onclick="window.location.href='\/guestbook'">
                
                <i class="iconfont icon-chat"></i>
                
                留言板
            </span>
            
            <span class="link-child-btn" onclick="window.location.href='\/about'">
                
                <i class="iconfont icon-contacts"></i>
                
                关于本站
            </span>
            
        </div>
        
    </div>
    
</div></div>
                        <span class="site-title">
                            基于 LLaMA 和 LangChain 实践本地 AI 知识库
                        </span>
                    </div>
                    
                    
                    <div class="right-nav">
                        
                        <a class="menu-btn nav-btn travellings" title="开往-友链接力" href="https://www.travellings.cn/go.html" target="_blank">
                            <i class="iconfont icon-subway"></i>
                        </a>
                        
                        <div class="menu-btn nav-btn" title="随机前往一篇文章">
                            <i class="iconfont icon-shuffle"></i>
                        </div>
                        
                        <div class="menu-btn nav-btn" title="全站搜索">
                            <i class="iconfont icon-search"></i>
                        </div>
                        
                        <div class="menu-btn nav-btn" id="themeToggle" title="切换主题模式">
                            <i class="iconfont icon-sun" id="themeIcon"></i>
                        </div>
                        
                        <div id="open-control" class="menu-btn nav-btn pc" title="打开中控台">
                            <i class="iconfont icon-dashboard"></i>
                        </div>
                        
                        <div class="to-top menu-btn" title="返回顶部">
                            <div class="to-top-btn">
                                <span class="num">0</span>
                                <i class="iconfont icon-up"></i>
                            </div>
                        </div>
                        
                        <div class="menu-btn nav-btn mobile" title="打开菜单">
                            <i class="iconfont icon-toc"></i>
                        </div>
                    </div>
                </div>
            </nav>
            <div class="mobile-menu" id="mobileMenu">
    
    <div class="menu-mask"></div>
    <div class="menu-content s-card">
        
        <div class="close-control">
            <i class="iconfont icon-close"></i>
        </div>

        
        <div class="menu-list">
            
            <div class="menu-item">
                <span class="link-title">文库</span>
                
                <div class="link-child">
                    
                    <div class="link-child-btn" onclick="window.location.href='\/'">
                        
                        <i class="iconfont icon-home"></i>
                        
                        <span class="name">文章列表</span>
                    </div>
                    
                    <div class="link-child-btn" onclick="window.location.href='\/categories'">
                        
                        <i class="iconfont icon-folder"></i>
                        
                        <span class="name">全部分类</span>
                    </div>
                    
                    <div class="link-child-btn" onclick="window.location.href='\/tags'">
                        
                        <i class="iconfont icon-hashtag"></i>
                        
                        <span class="name">全部标签</span>
                    </div>
                    
                </div>
                
            </div>
            
            <div class="menu-item">
                <span class="link-title">书影音</span>
                
                <div class="link-child">
                    
                    <div class="link-child-btn" onclick="window.location.href='\/reading'">
                        
                        <i class="iconfont icon-books"></i>
                        
                        <span class="name">读书</span>
                    </div>
                    
                    <div class="link-child-btn" onclick="window.location.href='\/watching'">
                        
                        <i class="iconfont icon-tv"></i>
                        
                        <span class="name">观影</span>
                    </div>
                    
                    <div class="link-child-btn" onclick="window.location.href='\/listening'">
                        
                        <i class="iconfont icon-music"></i>
                        
                        <span class="name">听歌</span>
                    </div>
                    
                </div>
                
            </div>
            
            <div class="menu-item">
                <span class="link-title">友链</span>
                
                <div class="link-child">
                    
                    <div class="link-child-btn" onclick="window.location.href='\/friends'">
                        
                        <i class="iconfont icon-people"></i>
                        
                        <span class="name">友情链接</span>
                    </div>
                    
                </div>
                
            </div>
            
            <div class="menu-item">
                <span class="link-title">关于</span>
                
                <div class="link-child">
                    
                    <div class="link-child-btn" onclick="window.location.href='\/guestbook'">
                        
                        <i class="iconfont icon-chat"></i>
                        
                        <span class="name">留言板</span>
                    </div>
                    
                    <div class="link-child-btn" onclick="window.location.href='\/about'">
                        
                        <i class="iconfont icon-contacts"></i>
                        
                        <span class="name">关于本站</span>
                    </div>
                    
                </div>
                
            </div>
            
        </div>
    </div>
</div>

<style>
.mobile-menu {
    position: fixed;
    top: 0;
    left: 0;
    width: 100vw;
    height: 100vh;
    z-index: 3000;
    display: none;
}

.mobile-menu .menu-mask {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: -1;
    background-color: var(--main-mask-background);
}

.mobile-menu .menu-content {
    position: absolute;
    top: 0;
    right: 0;
    height: 100%;
    width: 100%;
    max-width: 300px;
    border-radius: 12px 0 0 12px;
    padding: 20px;
    overflow: auto;
}

.mobile-menu .close-control {
    position: absolute;
    top: 10px;
    right: 20px;
    display: flex;
    align-items: center;
    justify-content: center;
    width: 35px;
    height: 35px;
    padding: 0;
    transition: background-color 0.3s, opacity 0.3s;
    border-radius: 50%;
    cursor: pointer;
}

.mobile-menu .close-control .iconfont {
    font-size: 18px;
    line-height: 1;
    color: var(--main-font-second-color);
    transition: color 0.3s, opacity 0.3s;
}

.mobile-menu .close-control:hover {
    background-color: var(--main-color);
}

.mobile-menu .close-control:hover .iconfont {
    color: var(--main-card-background);
}

.mobile-menu .menu-list {
    margin-top: 40px;
}

.mobile-menu .menu-item {
    margin-bottom: 12px;
}

.mobile-menu .menu-item .link-title {
    font-size: 14px;
    margin-bottom: 12px;
    display: inline-block;
    color: var(--main-font-second-color);
}

.mobile-menu .menu-item .link-child {
    display: grid;
    gap: 12px;
    grid-template-columns: 1fr 1fr;
}

.mobile-menu .menu-item .link-child-btn {
    display: flex;
    flex-direction: row;
    justify-content: flex-start;
    align-items: center;
    border-radius: 8px;
    padding: 10px 12px;
    background-color: var(--main-card-background);
    border: 1px solid var(--main-card-border);
    box-shadow: 0 8px 16px -4px var(--main-border-shadow);
    font-size: 15px;
    cursor: pointer;
    transition: all 0.3s;
}

.mobile-menu .menu-item .link-child-btn:hover {
    background-color: var(--main-color);
    color: var(--main-card-background);
}

.mobile-menu .menu-item .link-child-btn .iconfont {
    margin-right: 6px;
    opacity: 0.6;
}

.mobile-menu .menu-item .link-child-btn .name {
    max-width: 80px;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}
</style>

<script>
function toggleMobileMenu() {
    const mobileMenu = document.getElementById('mobileMenu');
    if (mobileMenu) {
        mobileMenu.style.display = mobileMenu.style.display === 'none' ? 'block' : 'none';
    }
}
</script> <div class="modal search-modal" id="searchModal">
  <div class="modal-container">
    <div class="modal-header">
      <div class="modal-title">
        <i class="iconfont icon-search"></i>
        <span>全局搜索</span>
      </div>
      <div class="modal-close">
        <i class="iconfont icon-close"></i>
      </div>
    </div>

    <div class="search-container">
      <div class="search-box">
        <input 
          type="text" 
          id="searchInput"
          placeholder="想要搜点什么" 
          autocomplete="off"
          autofocus
        >
      </div>

      <div class="search-results" id="searchResults">
        <div class="no-result" id="noResult" style="display: none;">
          <i class="iconfont icon-search-empty"></i>
          <span class="text">搜索结果为空</span>
        </div>
        <div class="search-list" id="searchList"></div>
      </div>

      <div class="search-stats">
        <span class="text" id="searchStats"></span>
      </div>
    </div>
  </div>
</div>

<style>
.search-modal {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background-color: rgba(0, 0, 0, 0.5);
  z-index: 999;
  display: none;
}

.modal-container {
  position: relative;
  width: 90%;
  max-width: 768px;
  margin: 80px auto;
  background-color: var(--main-card-background);
  border-radius: 12px;
  padding: 1.5rem;
}

.modal-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
}

.modal-title {
  display: flex;
  align-items: center;
  font-size: 1.2rem;
  font-weight: bold;
}

.modal-title .iconfont {
  margin-right: 0.5rem;
}

.modal-close {
  cursor: pointer;
  padding: 0.5rem;
}

.search-box input {
  width: 100%;
  outline: none;
  border-radius: 8px;
  font-size: 16px;
  padding: 0.6rem 1rem;
  color: var(--main-font-color);
  font-family: var(--main-font-family);
  border: 1px solid var(--main-card-border);
  background-color: var(--main-card-second-background);
  transition: border-color 0.3s, box-shadow 0.3s;
}

.search-box input:focus {
  border-color: var(--main-color);
  box-shadow: 0 8px 16px -4px var(--main-color-bg);
}

.search-results {
  margin-top: 20px;
  min-height: 300px;
}

.no-result {
  height: 300px;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}

.no-result .iconfont {
  font-size: 40px;
  margin-bottom: 12px;
}

.no-result .text {
  font-size: 18px;
  opacity: 0.6;
}

.search-list .search-item {
  margin-bottom: 12px;
  padding: 1rem;
  border-radius: 8px;
  background-color: var(--main-card-second-background);
  cursor: pointer;
  transition: transform 0.3s;
}

.search-list .search-item:hover {
  transform: translateY(-2px);
}

.search-item .title {
  font-size: 16px;
  margin-bottom: 6px;
}

.search-item .content {
  color: var(--main-font-second-color);
  font-size: 14px;
  margin-top: 8px;
}

.search-stats {
  margin-top: 1rem;
  font-size: 14px;
  color: var(--main-font-second-color);
}

.highlight {
  color: var(--main-color);
  background: transparent;
}
</style> </header>

        
        <main class="main-layout">



<div class="post">
    <div class="post-meta">
        <div class="meta">
            
            <div class="categories">
                
                
                <a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80" class="cat-item">
                    <i class="iconfont icon-folder"></i>
                    <span class="name">编程语言</span>
                </a>
                
                
            </div>
            
            <div class="tags">
                
                
                <a href="/tags/llama" class="tag-item">
                    <i class="iconfont icon-hashtag"></i>
                    <span class="name">LLaMA</span>
                </a>
                
                <a href="/tags/langchain" class="tag-item">
                    <i class="iconfont icon-hashtag"></i>
                    <span class="name">LangChain</span>
                </a>
                
                <a href="/tags/rag" class="tag-item">
                    <i class="iconfont icon-hashtag"></i>
                    <span class="name">RAG</span>
                </a>
                
                <a href="/tags/gpts" class="tag-item">
                    <i class="iconfont icon-hashtag"></i>
                    <span class="name">GPTs</span>
                </a>
                
                
            </div>
        </div>
        <h1 class="title">
            基于 LLaMA 和 LangChain 实践本地 AI 知识库
        </h1>
        <div class="other-meta">
            
            <span class="meta date">
                <i class="iconfont icon-date"></i>
                2024-02-29
            </span>
            
            <span class="update meta">
                <i class="iconfont icon-time"></i>
                2024-02-29
            </span>
            
            <span class="hot meta">
                <i class="iconfont icon-fire"></i>
                <span id="twikoo_visitors" class="artalk-pv-count">0</span>
            </span>
            
            <span class="chat meta hover" data-scroll-to="comments">
                <i class="iconfont icon-chat"></i>
                <span id="twikoo_comments" class="artalk-comment-count">0</span>
            </span>
        </div>
    </div>
    <div class="post-content">
        <article class="post-article s-card">
            
            
            
            <div class="expired s-card">
                本文发表于 <strong>393</strong> 天前，其中的信息可能已经事过境迁
            </div>
            

            
<div class="article-gpt s-card">
  <div class="title">
    <span class="name">
      <i class="iconfont icon-robot"></i>
      文章摘要
      <i class="iconfont icon-up"></i>
    </span>
    <span class="logo">FakeGPT</span>
  </div>
  <div class="content s-card">
    <span class="text"></span>
  </div>
  <div class="meta">
    
    
  </div>
</div>
<script src="https://npm.elemecdn.com/typeit@8.7.1/dist/index.umd.js"></script>
<script>
document.addEventListener("DOMContentLoaded", function () {
    new TypeIt(".article-gpt .content .text", {
        strings: '本文讨论了人工智能领域的最新发展，主要围绕着基于 Transformer 和 MoE 架构的多模态模型 Gemini 1.5 Pro，以及 OpenAI 推出的支持从文字生成视频的模型 Sora。文章提到通用人工智能（AGI）的实现正在加速，指出 AI 应用落地的主要实践围绕大模型微调、提示词工程和知识增强展开。在介绍 LangChain 中的知识库构建过程中，涉及Loader、Splitter、Embeddings 和 VectorStore 等步骤。此外，还讨论了 RAG 和 GPTs 在实践中的应用，以及LangChain 中的 Chain 概念，以及如何将其与大语言模型和知识库结合以实现 Q\u0026A 和 对话式检索。文章最后呼吁关注LangChain 的最新发展和替代品 AutoChain、Embedchain。',
        speed: 10,
        lifeLike: true,
        waitUntilVisible: true,
    }).go();
});
</script>



            
            <div id="page-content" class="markdown-main-style">
                <p>有时候，我难免不由地感慨，真实的人类世界，本就是一个巨大的娱乐圈，即使是在英雄辈出的 IT 行业。数日前，Google 正式对外发布了 Gemini 1.5 Pro，一个建立在 Transformer 和 MoE 架构上的多模态模型。可惜，这个被 Google 寄予厚望的产品并未激起多少水花，因为就在同一天 OpenAI 发布了 Sora，一个支持从文字生成视频的模型，可谓是一时风光无二。有人说，OpenAI 站在 Google 的肩膀上，用 Google 的技术疯狂刷屏。此中曲直，远非我等外人所能预也。我们唯一能确定的事情是，通用人工智能，即：AGI（<strong>Artificial General Intelligence</strong>）的实现，正在以肉眼可见的速度被缩短，以前在科幻电影中看到的种种场景，或许会比我们想象中来得更快一些。不过，等待 AGI 来临前的黑夜注定是漫长而孤寂的。在此期间，我们继续来探索 AI 应用落地的最佳实践，即：在成功部署本地 AI 大模型后，如何通过外挂知识库的方式为其 “<strong>注入</strong>” 新的知识。</p>
<h1 id="从-rag--gpts-开始">从 RAG &amp; GPTs 开始</h1>
<p>在上一期博客中，博主曾经有一个困惑，那就是当前阶段 AI 应用的最佳实践到底是什么？站在 2023 年的时间节点上，博主曾经以为未来属于提示词工程(<strong>Prompt Engineering</strong>)，而站在 2024 年的时间节点上，博主认为 <strong>RAG &amp; GPTs</strong> 在实践方面或许要略胜一筹。在过去的一年里，我们陆陆续续看到像 <a href="https://promptheroes.cn/">Prompt Heroes</a>、<a href="https://promptbase.cn/">PromptBase</a>、<a href="https://www.aishort.top/">AI Short</a>&hellip;等等这样的提示词网站出现，甚至提示词可以像商品一样进行交易。与此同时，随着 OpenAI <a href="https://openai.com/blog/introducing-the-gpt-store">GPT Store</a> 的发布，我们仿佛可以看到一种 AI 应用商店的雏形。什么是 GPTs 呢？通常是指可以让使用者量身定做 AI 助理的工具。譬如，它允许用户上传资料来丰富 ChatGPT 的知识库，允许用户使用个性化的提示词来指导 ChatGPT 的行为，允许用户整合各项技能(搜索引擎、Web API、<a href="https://cookbook.openai.com/examples/function_calling_with_an_openapi_spec">Function Calling</a>)&hellip;等等。我们在上一期博客中提到人工智能的 “<strong>安卓时刻</strong>”，一个重要的契机是目前产生了类似应用商店的 GPT Store，如下图所示：</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/ChatGPT-GPT-Store.png" alt="OpenAI 推出 GPT Store"></p>
<p>如果你觉得 OpenAI 的 GPT Store 离我们还稍微有点距离的话，不妨了解一下 <a href="https://github.com/labring/FastGPT">FastGPT</a> 这个项目，它以更加直观的方式展示了一个 GPTs 是如何被创造出来的。如图所示，博主利用我的博客作为知识库创建了一个博客助手，而这一切只需要选模型、编写提示词、上传资料三个步骤即可。感兴趣的朋友可以从 <a href="https://share.fastgpt.in/chat/share?shareId=rrpn95r7p7x0mc50fvofkgfn">这里</a> 进行体验：</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/FastGPT-GPTs.png" alt="通过 FastGPT 创建 AI 应用"></p>
<p>由此，我们就可以得出一个结论，目前 AI 应用落地主要还是围绕大模型微调(<strong>Fine Tuning</strong>)、提示词工程(<strong>Prompt Engineering</strong>) 以及知识增强展开，并且 GPTs 里依然有提示词参与，两者并不冲突。考虑到，大模型微调这条线存在一定的门槛，我们暂且将其放在一旁。此时，提示词工程和知识增强就成为了 AI 应用落地的关键。知识增强，专业术语为<strong>检索增强生成</strong>，即：<strong>Retrieval-Augmented Generation</strong>，<strong>RAG</strong>，其基本思路就是将大语言模型和知识库结合起来，通过外挂知识库的方式来增强大模型的生成能力。比如微软的 New Bing 是 GPT-4 + 搜索引擎的方案，而更一般的方案则是 LLM + 向量数据库的思路，下图展示了 RAG 运作的基本原理：</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/LangChain-Flow.drawio.png" alt="RAG 运作的基本原理"></p>
<p>从这个角度来看，<a href="https://github.com/langchain-ai/langchain">LangChain</a> 及其衍生项目 <a href="https://github.com/Forethought-Technologies/AutoChain">AutoChain</a>、<a href="https://github.com/embedchain/embedchain">Embedchain</a>，甚至 <a href="https://github.com/labring/FastGPT">FastGPT</a> 等项目解决的本质都是 <strong>RAG</strong> 和 <strong>Agent</strong> 的问题。其中，<strong>Agent</strong> 不在本文的讨论范围内，这里博主不打算详细展开。接下来的内容，博主会按照这个思路进行阐述，并且以 LangChain 为例来对其中的细节进行说明。</p>
<h1 id="知识库构建">知识库构建</h1>
<p>如你所见，RAG 由 LLM 和 知识库两部分组成。首先，我们来构建知识库，通常，这个过程可以划分为下面四个步骤，即：载入文档(<strong>Loader</strong>)、拆分文本(<strong>Splitter</strong>)、文本向量化(<strong>Embeddings</strong>)、向量存储(<strong>VectorStore</strong>)。</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/langchain_text_indexing.png" alt="构建知识库的步骤"></p>
<h2 id="loader">Loader</h2>
<p>你会注意到，博主在文章中加粗显示了这四个步骤的英文描述，事实上，这代表了 LangChain 中的一部分概念，以 <a href="https://python.langchain.com/docs/modules/data_connection/document_loaders/">Loader</a> 为例，它负责从各种文档中载入内容，下面展示了从文本文件、PDF 文件以及网页中载入内容：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">TextLoader</span><span class="p">,</span> <span class="n">PyPDFLoader</span><span class="p">,</span> <span class="n">WebBaseLoader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># TextLoader</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 指定编码</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">TextLoader</span><span class="p">(</span><span class="s2">&#34;./input/金庸武侠小说全集/射雕英雄传.txt&#34;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 自动推断</span>
</span></span><span class="line"><span class="cl"><span class="c1"># python -m pip install chardet</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">TextLoader</span><span class="p">(</span><span class="s2">&#34;./input/金庸武侠小说全集/射雕英雄传.txt&#34;</span><span class="p">,</span> <span class="n">autodetect_encoding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># PyPDFLoader</span>
</span></span><span class="line"><span class="cl"><span class="c1"># python -m pip install pypdf</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">PyPDFLoader</span><span class="p">(</span><span class="s2">&#34;./input/文学作品/追风筝的人.pdf&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># WebBaseLoader</span>
</span></span><span class="line"><span class="cl"><span class="c1"># python -m pip install beautifulsoup4</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">WebBaseLoader</span><span class="p">(</span><span class="n">web_paths</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;https://blog.yuanpei.me&#39;</span><span class="p">,),</span> <span class="n">bs_kwargs</span><span class="o">=</span><span class="p">{})</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span></code></pre></div><p>当然，现实中通常会有很多文档，此时，我们可以使用 <a href="https://python.langchain.com/docs/modules/data_connection/document_loaders/file_directory">DirectoryLoader</a> 来一次性载入多个文档：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="s2">&#34;./posts/&#34;</span><span class="p">,</span> <span class="n">glob</span><span class="o">=</span><span class="s2">&#34;*.md&#34;</span><span class="p">,</span> <span class="n">loader_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">silent_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><p>默认情况下，DirectoryLoader 使用 <a href="https://python.langchain.com/docs/integrations/document_loaders/unstructured_file">UnstructuredFileLoader</a> 这个通用的 Loader 来兼容各种格式的文件，不过，你依然可以使用 loader_cls 参数来指定 Loader 类型：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span><span class="p">,</span> <span class="n">TextLoader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="s2">&#34;./posts/&#34;</span><span class="p">,</span> <span class="n">glob</span><span class="o">=</span><span class="s2">&#34;*.md&#34;</span><span class="p">,</span> <span class="n">loader_cls</span><span class="o">=</span><span class="n">TextLoader</span><span class="p">,</span> <span class="n">loader_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">silent_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="splitter">Splitter</h2>
<p>调用 Loader 的 load() 方法，返回的是一组 Document 的集合。此时，我们可以将这些 Document 交给 <a href="https://python.langchain.com/docs/modules/data_connection/document_transformers/">TextSplitter</a> 来对分本内容的分割，因为我们最终需要对文本块做向量化处理：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span><span class="p">,</span> <span class="n">RecursiveCharacterTextSplitter</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">separator</span> <span class="o">=</span> <span class="s2">&#34;</span><span class="se">\n\n</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">600</span><span class="p">,</span> <span class="n">chunk_overlap</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">length_function</span> <span class="o">=</span> <span class="nb">len</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</span></span></code></pre></div><p>这里，博主先后使用了 CharacterTextSplitter 和 RecursiveCharacterTextSplitter 两种 Splitter，两者的区别是：CharacterTextSplitter 会将文本按照单个字符进行分割，而 RecursiveCharacterTextSplitter 则会将文本按照连续的多个字符进行分割。不过，经过博主的测试，两种分割方式最终对 LLM 的影响微乎其微，大家可以参照官方文档中的说明，选择符合个人预期的分割方法：</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/LangChain_TextSplitter.png" alt="LangChain 中不同的 TextSplitter"></p>
<p>按照一般的流程，我们只需要按下面的方式，即可完成文档的分割：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span><span class="err">。</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</span></span></code></pre></div><p>不过，实际操作中更推荐使用 <code>load_and_Split()</code> 方法，两步合并为一步，更简洁一点：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load_and_split</span><span class="p">(</span><span class="n">text_splitter</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="embeddings">Embeddings</h2>
<p>经过 Splitter 处理以后，我们将得到一系列文本块，它依然是一组 Document 集合。此时，便轮到 <a href="https://python.langchain.com/docs/modules/data_connection/text_embedding/">Embeddings</a> 出场，它将负责将文本块向量化。这里，博主使用的是 <a href="https://python.langchain.com/docs/integrations/platforms/huggingface#huggingfaceembeddings">HuggingFaceEmbeddings</a>，首次运行它会自动下载模型文件。当然，我天朝上国自有国情在此，从 <a href="https://huggingface.co/">Hugging Face</a> 下载模型的问题在 AI 的道路上可谓是阴魂不散。因此，下面演示的是，通过镜像站来下载模型的方法。考虑到，默认的 <a href="https://hf-mirror.com/sentence-transformers/all-mpnet-base-v2">sentence-transformers/all-mpnet-base-v2</a> 模型是英文模型，我们引入一个对中文更友好的 <a href="https://hf-mirror.com/GanymedeNil/text2vec-large-chinese">GanymedeNil/text2vec-large-chinese</a> 模型:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_community.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;HF_ENDPOINT&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;https://hf-mirror.com&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;GanymedeNil/text2vec-large-chinese&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 单个句子</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="s2">&#34;人生若只如初见，何事秋风悲画扇&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 多个句子</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="s2">&#34;人生若只如初见，何事秋风悲画扇&#34;</span><span class="p">,</span><span class="s2">&#34;等闲变却故人心，却道故人心易变&#34;</span><span class="p">]))</span>
</span></span></code></pre></div><p>当然，从最终向量化以后的结果来看，前者的向量维数只有 768，而后者则可以达到 1024。至此，我们就完成文本内容的向量化。一旦所有的文本信息都被转换为向量数据，此时，信息检索就完完全全地变成了一道数学题，由向量的余弦公式，我们可以非常容易地计算出两个向量间的夹角，这个夹角越小，则表明两个向量越相近。这就是向量相似性检索的基本原理，在此前的文章《视频是不能 P 的系列：使用 Milvus 实现海量人脸快速检索》一文中，博主曾经尝试利用这种思路来优化人脸识别效率，不知道大家是否还留下印象🙃&hellip;</p>
<h2 id="vectorstore">VectorStore</h2>
<p>OK，当我们将文本信息转化为向量以后，就需要考虑如何储存这些向量信息，如上文中给出的图片所示，LangChain 中支持诸如 <a href="https://github.com/facebookresearch/faiss">FAISS</a>、<a href="https://milvus.io/">Milvus</a>、<a href="https://www.pinecone.io/">Pinecone</a>、<a href="https://github.com/chroma-core/chroma">Chroma</a>&hellip;等多种向量数据库，以及像
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html">Elasticsearch</a>、<a href="https://github.com/pgvector/pgvector">PostgreSQL</a> 这样的具备向量存储能力的传统数据库，我们可以根据自己的需求选择合适的存储方案。为了方便演示，这里我们使用 Facebook 出品的 <a href="https://github.com/facebookresearch/faiss">FAISS</a>，它不需要像 Milvus 那样准备额外的环境，使用体验上更接近 SQLite 这种嵌入式的数据库。当然，如果你比较中意于 <a href="https://github.com/chroma-core/chroma">Chroma</a>，一切行止由心，LangChain 在自由度上拉满：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_community.vectorstores.faiss</span> <span class="kn">import</span> <span class="n">FAISS</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pickle</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># python -m pip install faiss-cpu</span>
</span></span><span class="line"><span class="cl"><span class="n">vector_store</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./output/&lt;Your-Persistence-Path&gt;&#39;</span><span class="p">,</span> <span class="s2">&#34;wb&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vector_store</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></span></code></pre></div><p>FastGPT 中创建知识库的过程，原理完全相同，它支持从文档或者网址构建知识库，最终将向量化数据存储在 MonggoDB 中，目前，这个项目使用的 FastAI 4K 模型来源不明，而 Embedding-2 模型则是来自于 OpenAI。所以，<a href="https://cloud.fastgpt.in/">FastGPT</a> 这个网站最大的资金消耗主要来自 FastAI，目测是一个独立训练出来的私有模型。下图展示了博主在本地构建知识库的过程，如你所见，博主使用了 263 篇博客的内容来构建这个知识库：</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/knowledge-base-build-output.png" alt="本地知识库构建过程"></p>
<h1 id="llama-的再度整合">LLaMA 的再度整合</h1>
<p>坦白讲，纯 CPU 环境下的知识库非常花时间，譬如，博主使用 1024 个维度的向量来储存金庸先生的 15 部小说，经序列化后的文件体积高达 1.2G。果然，大模型相关的一切事物都非常庞大，这或许能帮大家理解类似 7B、13B、60B&hellip;等等的大模型的本质，因为它们同样是由大量的高精度的、浮点型的向量数据构成。可偏偏就是这些对人类来说毫无意义、宛如天书一般的数字，能够从你的只言片语中“<strong>理解</strong>”你的意图，回应你的各种输入，难道你还能笃定，这一切不是某种魔法，而提示词不过是施展魔法时吟唱的咒语？从这个角度来看，RAG 是什么呢？RAG 更像是你在吟唱咒语时随手拿一本魔法书在手里，你随时可以从这本魔法书里查询资料完善咒语。</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/langchain_retrieval_and_generate.png" alt="RAG 如何工作"></p>
<h2 id="rag-与-prompt">RAG 与 Prompt</h2>
<p>现在，我们顺着这个思路，将 LLaMA 和 LangChain 结合起来，这里的 LLaMA 指的是 <strong>llama.cpp</strong> + <strong>Qwen-1_8B-Chat</strong>，这个方案我们在上一期博客已经介绍过了，这里不再赘述。我们先来看看 Retrieve 的过程，即：如何从向量数据库中找到问题相关的内容，显然，这是 RAG 里的第一步：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;./output/个人博客.pkl&#34;</span><span class="p">,</span> <span class="s2">&#34;rb&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;Envoy 在微服务中的应用场景有哪些&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="n">topK</span> <span class="o">=</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 普通的相似性检索</span>
</span></span><span class="line"><span class="cl">    <span class="n">result</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">topK</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 带有分数的相似性检索</span>
</span></span><span class="line"><span class="cl">    <span class="n">result</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">similarity_search_with_relevance_scores</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">topK</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 最大边界相关性检索</span>
</span></span><span class="line"><span class="cl">    <span class="n">result</span> <span class="o">=</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">max_marginal_relevance_search</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">topK</span><span class="p">)</span>
</span></span></code></pre></div><p>这里，博主例举出了常用的向量相似性检索的方法，大家可以参考 <a href="https://python.langchain.com/docs/integrations/vectorstores">官方文档</a> 选择合适的方法，通常情况下，使用 <code>similarity_search()</code> 方法即可；可有时候向量数据库会检索出与问题相关性不强的内容，此时，就需要使用 <code>similarity_search_with_relevance_scores()</code> 配合某个阈值进行处理；第三种方法，我个人感觉，其返回结果的相关性不如前两种方法。还是那句话，目前博主的 AI 道路还在摸索阶段，大家酌情使用即可。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.prompts.prompt</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义提示词模板</span>
</span></span><span class="line"><span class="cl"><span class="n">PROMPT_TEMPLATE</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">You are a helpful AI bot. Your name is </span><span class="si">{name}</span><span class="s2">.
</span></span></span><span class="line"><span class="cl"><span class="s2">Please answer the question only based on the following context:
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{context}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">If the question is about your identity or role or name, answer &#39;</span><span class="si">{name}</span><span class="s2">&#39; directly, no need to refer to the context.
</span></span></span><span class="line"><span class="cl"><span class="s2">If the context is not enough to support the generation of an answer, Please return &#34;I&#39;m sorry, I can&#39;t answer your question.&#34; immediately.
</span></span></span><span class="line"><span class="cl"><span class="s2">You have an opportunity to refine the existing answer (only if needed) with current context.
</span></span></span><span class="line"><span class="cl"><span class="s2">You must always answer the question in Chinese.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">Queation: </span><span class="si">{question}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 根据问题做相似性检索</span>
</span></span><span class="line"><span class="cl"><span class="n">question</span> <span class="o">=</span> <span class="s2">&#34;Envoy在微服务中都有哪些应用场景&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">vector_store</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">context</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">document</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 从模板创建提示词并填充模板</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">PROMPT_TEMPLATE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">query</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;ChatGPT&#34;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</span></span></code></pre></div><p>RAG 中的 A 是指 Augmented，表示增强的，这个增强体现在哪里呢？答案是提示词。如图所示，在这段提示词里面，博主试图让大语言模型假扮 ChatGPT，同时告诉它按照给定的上下文来回答问题，并且要求它必须使用中文进行回答。通过这段代码，我们就可以产生符合我们预期的输入，而接下来，我们只需要将其传递给大语言模型即可。除了这种方式以外，我们还可以按 OpenAI 的规范，使用 <code>ChatPromptTemplate</code> 来组织提示词：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义提示词模板</span>
</span></span><span class="line"><span class="cl"><span class="n">PROMPT_TEMPLATE</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">You are a helpful AI bot. Your name is </span><span class="si">{name}</span><span class="s2">.
</span></span></span><span class="line"><span class="cl"><span class="s2">Please answer the question only based on the following context:
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{context}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">If the question is about your identity or role or name, answer &#39;</span><span class="si">{name}</span><span class="s2">&#39; directly, no need to refer to the context.
</span></span></span><span class="line"><span class="cl"><span class="s2">If the context is not enough to support the generation of an answer, Please return &#34;I&#39;m sorry, I can&#39;t answer your question.&#34; immediately.
</span></span></span><span class="line"><span class="cl"><span class="s2">You have an opportunity to refine the existing answer (only if needed) with current context.
</span></span></span><span class="line"><span class="cl"><span class="s2">You must always answer the question in Chinese. 
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 根据问题做相似性检索</span>
</span></span><span class="line"><span class="cl"><span class="n">question</span> <span class="o">=</span> <span class="s2">&#34;Envoy在微服务中都有哪些应用场景&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">vector_store</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">context</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">document</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 从模板创建提示词并填充模板</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="n">PROMPT_TEMPLATE</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;</span><span class="si">{question}</span><span class="s2">&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">query</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;ChatGPT&#34;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</span></span></code></pre></div><p>显而易见，第二种更好一点，因为它可以将问题和上下文显著地区分开来。当然，为了让 LLM 确信它就是 ChatGPT，博主在提示词工程上可没少下功夫。这其实佐证了博主一开始的观点：<strong>2023 年的提示词工程，2024 年的 GPTs，这两者并不冲突，而是一种相辅相成的关系</strong>。RAG 中的 Retrieve 和 Augmented 现在都已先后登场， 最后这个 G 自然是指 Generation，理论上剩下的工作交给 LLM 即可。可是如何你仔细想想，就会发现这里隐含着两个问题，<strong>其一是从向量数据库中检索到的信息，有一定的可能性超过 LLM 的上下文长度；其二是对上下文的约束越严格，LLM 就越显得 “弱智”，你必须要在发散和收敛中做出选择。以一言蔽之，LLM 有幻觉固然不好，可如果缺乏想象力，一切只怕是会变得更糟糕</strong>！不知大家是如何考虑这个问题的呢？</p>
<h2 id="langchain-中的-chain">LangChain 中的 Chain</h2>
<p>在 LangChain 的诸多概念中，Chain 或许是最抽象、最重要的哪一个，因为它就像一个管道一样，可以讲我们这篇文章中提到的各种组件串联起来。譬如， <code>LLMChain</code> 可以将一个LLM 和 Prompt 串联起来，<code>RetrievalQA</code> 可以配合 LLM 和知识库实现简单的 Q&amp;A，<code>ConversationalRetrievalChain</code> 可以配合 LLM、知识库和聊天历史实现对话式检索。起初，我对于 <code>RetrievalQA</code> 这个类是极其排斥和反感的，因为它不论是看起来还是用起来，都像极了一个 Chain，可它就偏偏不是一个 Chain，真是奇哉怪也！</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMChain</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_community.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&#34;Tell me a </span><span class="si">{adjective}</span><span class="s2"> joke&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;adjective&#34;</span><span class="p">],</span> 
</span></span><span class="line"><span class="cl">    <span class="n">template</span><span class="o">=</span><span class="n">prompt_template</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(),</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
</span></span></code></pre></div><p>刚刚提到，我们大体上有两种方式来将 LLM 和 LangChain 结合起来，一种是基本的 Q&amp;A，一种是对话式检索。其中，<code>streaming</code> 参数用于支持流式返回，<code>return_source_documents</code> 参与用于控制是否返回引用的文档信息，<code>ConversationBufferMemory</code> 组件用于处理对话历史。下面给出具体的实现代码：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 基本的 Q&amp;A</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_basic_qa_chain</span><span class="p">(</span><span class="n">baseUrl</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">apiKey</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">storeFilePath</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;gpt-3.5-turbo&#34;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">openai_api_base</span><span class="o">=</span><span class="n">baseUrl</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">openai_api_key</span><span class="o">=</span><span class="n">apiKey</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">streaming</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">retriever</span> <span class="o">=</span> <span class="n">load_retriever</span><span class="p">(</span><span class="n">storeFilePath</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">chain</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">chain_type</span><span class="o">=</span><span class="s2">&#34;stuff&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">return_source_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">chain</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 对话式检索</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_conversational_retrieval_chain</span><span class="p">(</span><span class="n">baseUrl</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">apiKey</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">storeFilePath</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;gpt-3.5-turbo&#34;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">openai_api_base</span><span class="o">=</span><span class="n">baseUrl</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">openai_api_key</span><span class="o">=</span><span class="n">apiKey</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">streaming</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">retriever</span> <span class="o">=</span> <span class="n">load_retriever</span><span class="p">(</span><span class="n">storeFilePath</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">memory_key</span><span class="o">=</span><span class="s2">&#34;chat_history&#34;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">return_messages</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">input_key</span><span class="o">=</span><span class="s2">&#34;question&#34;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">output_key</span><span class="o">=</span><span class="s2">&#34;source_documents&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">chain</span> <span class="o">=</span> <span class="n">ConversationalRetrievalChain</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">return_source_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">chain</span>
</span></span></code></pre></div><p>现在，我们就可以调用 Chain 来和大语言模型及知识库进行交互：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 构造 Chain，使用本地模型</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">get_conversational_retrieval_chain_</span><span class="p">(</span><span class="s2">&#34;http://localhost:8080/v1/&#34;</span><span class="p">,</span> <span class="s1">&#39;sk-1234567890&#39;</span><span class="p">,</span>  <span class="s1">&#39;./output/个人博客.pkl&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 根据问题做相似性检索</span>
</span></span><span class="line"><span class="cl"><span class="n">question</span> <span class="o">=</span> <span class="s2">&#34;Envoy在微服务中都有哪些应用场景&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">vector_store</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">context</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">document</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 从模板创建提示词并填充模板</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="n">PROMPT_TEMPLATE</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;</span><span class="si">{question}</span><span class="s2">&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">query</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;ChatGPT&#34;</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 方式一： 同步调用</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 方式二： 流式调用</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</span></span></code></pre></div><p>如下图所示，在经过反复地调试和优化以后，我们可以针对博客中的内容进行提问，并且程序会返回与问题相关的文档信息，这个结果整体而言还是挺不错的。当然，距离 FastGPT 这种相对完善的产品还是挺遥远的，使用 CPU 进行推理的 llama.cpp 除了生成速度慢以外，还会出现缓存 <code>kv cache</code> 不足的问题。庆幸的是，在折腾 LangChain 的过程中，逐渐理解了 RAG 以及 LangChain 的整体思路。在 LangChain 的 <a href="https://python.langchain.com/docs/expression_language/cookbook/">官方文档</a> 中，官方提供了使用 LangChain 落地 AI 应用的示例，这篇文章主要参考了 <a href="https://python.langchain.com/docs/expression_language/cookbook/retrieval">RAG</a> 这一篇，大家可以特别关注一下。</p>
<p><img src="/posts/%E5%9F%BA%E4%BA%8E-LLaMA-%E5%92%8C-LangChain-%E5%AE%9E%E8%B7%B5%E6%9C%AC%E5%9C%B0-AI-%E7%9F%A5%E8%AF%86%E5%BA%93/LlmChain_Chat_Output.png" alt="本地 AI 知识库运行结果展示"></p>
<p>LangChain 除了概念多以外，API 变动非常频繁，经常出现破坏性的变更，而且官方现在主要在推 LangChain Expression Language(LCEL)，所以，网络上的资料经常都是过期的，建议大家有时间还是去看纯英文的官方文档。当然，大家有兴趣的话，可以考虑下 LangChain 的替代品，譬如 <a href="https://github.com/Forethought-Technologies/AutoChain">AutoChain</a> 和 <a href="https://github.com/embedchain/embedchain">Embedchain</a>，它们的 API 毫无疑问都比 LangChain 简单，实际使用情况，只有靠各位自己去体验啦，哈哈！</p>
<h1 id="本文小结">本文小结</h1>
<p>在探索 AI 的过程中，一个令人难过的事实是：为了创作这篇大约1.5万字的文章，博主先后花了一周左右的时间来做实验，然后花了两天的时间来形成文字，而在将这些博客内容 “<strong>投喂</strong>” 给 AI 以后，它可以迅速 “<strong>描摹</strong>” 出我的轮廓。你不得不承认，这个世界的信息实在多到爆炸，以致于我们绝无可能构建出一个无穷大的知识库。AI 更像是这个复杂时代地观察者，可以帮助我们更快、更好地去理解这个世界，虽然这个代价是 AI 可能会产生更多噪音，这有一点像什么呢？就像你在看视频时开启倍速播放，或许你节省了时间、提升了节奏，可终究失去了某种身体力行的体验感，正如在这篇文章里，我使用 LLaMA 和 LangChain 实现 RAG 的过程，于屏幕前的你而言，不过是互联网海洋里鼠标轻轻掠起的浪花。对我而言，写作的整个过程，与 RAG 更是何其的相似，我在输出这篇文章的同时，查阅大量的资料，最终，它们成为了我认知、感悟以及价值观的一部分，而这，便是自我的增强。</p>

            </div>

            
            
            
<div class="copyright s-card">
  <div class="title">
    <span class="post-name">基于 LLaMA 和 LangChain 实践本地 AI 知识库</span>
    
    <a :href="http://localhost:1313/posts/practice-local-ai-knowledg-base-based-on-llama-and-langchain/" class="post-link" target="_blank">
      http://localhost:1313/posts/practice-local-ai-knowledg-base-based-on-llama-and-langchain/
    </a>
    
  </div>
  <div class="post-meta">
    <div class="meta-item">
      <span class="tip">作者</span>
      <span class="name">飞鸿踏雪</span>
    </div>
    
    <div class="meta-item">
      <span class="tip">发布于</span>
      <span class="name">2024-02-29</span>
    </div>
    
    
    <div class="meta-item">
      <span class="tip">更新于</span>
      <span class="name">2024-02-29</span>
    </div>
    
    
    <div class="meta-item cc">
      <span class="tip">许可协议</span>
      <a class="name" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" target="_blank">
        CC BY-NC-SA 4.0
      </a>
    </div>
    
  </div>
  <span class="meta-tip">署名-非商业性使用-相同方式共享 4.0 国际</span>
</div>

            

            
            <div class="other-meta">
                <div class="all-tags">
                    
                    
                    <a href="/tags/llama" class="tag-item">
                        <i class="iconfont icon-hashtag"></i>
                        <span class="name">LLaMA</span>
                    </a>
                    
                    <a href="/tags/langchain" class="tag-item">
                        <i class="iconfont icon-hashtag"></i>
                        <span class="name">LangChain</span>
                    </a>
                    
                    <a href="/tags/rag" class="tag-item">
                        <i class="iconfont icon-hashtag"></i>
                        <span class="name">RAG</span>
                    </a>
                    
                    <a href="/tags/gpts" class="tag-item">
                        <i class="iconfont icon-hashtag"></i>
                        <span class="name">GPTs</span>
                    </a>
                    
                    
                </div>
                <a href="https://eqnxweimkr5.feishu.cn/share/base/form/shrcnCXCPmxCKKJYI3RKUfefJre" 
                   class="report" 
                   target="_blank">
                    <i class="iconfont icon-report"></i>
                    反馈与投诉
                </a>
            </div>

            
            
<div class="reward">
  <div class="reward-btn" onclick="document.getElementById('rewardModal').style.display='block'">
    <i class="iconfont icon-reward"></i>
    <span class="text">赞赏博主</span>
  </div>

  
  <div id="rewardModal" class="modal" style="display: none;">
    <div class="modal-mask" onclick="document.getElementById('rewardModal').style.display='none'"></div>
    <div class="modal-container">
      <div class="modal-header">
        <span class="modal-title">
          <i class="iconfont icon-reward"></i>
          赞赏博主
        </span>
        <span class="modal-close" onclick="document.getElementById('rewardModal').style.display='none'">
          <i class="iconfont icon-close"></i>
        </span>
      </div>
      
      <div class="modal-content">
        <div class="reward-card">
          <span class="thank">🙏 感谢您赐予我前进的力量</span>
          <div class="qr">
            
            <a href="/images/reward/wechat.jpg" class="qr-img" target="_blank">
              <img src="/images/reward/wechat.jpg" alt="微信" />
              <span class="tip">
                <i class="iconfont icon-wechat-pay"></i>
                微信
              </span>
            </a>
            
            
            
            <a href="/images/reward/alipay.jpg" class="qr-img" target="_blank">
              <img src="/images/reward/alipay.jpg" alt="支付宝" />
              <span class="tip">
                <i class="iconfont icon-alipay"></i>
                支付宝
              </span>
            </a>
            
          </div>
          
          <div class="all-list s-card hover">
            <span class="title">全部赞赏者名单</span>
            <span class="tip">赞赏金额将全部用于开源项目维护，以及服务器、域名及各类云服务的开销</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<style>
.modal {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  z-index: 1000;
}

.modal-mask {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: rgba(0, 0, 0, 0.5);
  z-index: 1001;
}

.modal-container {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  max-width: 430px;
  width: 90%;
  background: var(--main-card-background);
  border-radius: 8px;
  padding: 20px;
  z-index: 1002;
}

.modal-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 20px;
}

.modal-close {
  cursor: pointer;
}

 
.reward {
  position: relative;
  display: flex;
  justify-content: center;
  width: max-content;
  margin: 1rem auto;
  user-select: none;
}

.reward-btn {
  display: flex;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  height: 40px;
  width: 120px;
  border-radius: 8px;
  color: #fff;
  background-color: var(--main-color-red);
  transition: box-shadow 0.5s;
  cursor: pointer;
}

 
</style>



            
            

            
            
  
  
  
  
  <div class="related-post">
    <div class="title">
      <span class="name">
        <i class="iconfont icon-star"></i>
        相关推荐
      </span>
      
      <span class="shuffle" onclick="window.location.href='\/posts\/169430744\/'">
        随便逛逛
      </span>
      
    </div>

    
    



<div class="post-list ">
    
    <article class="post-item s-card">
        
        
        
        <div class="content">
            
            <h2 class="title">
                <a href="/posts/semantic-kernel-mcp-agent-context-enhanced-exploration/">Semantic Kernel × MCP：智能体的上下文增强探索</a>
            </h2>
            
            
            <div class="summary">
                
                    本文深入探讨了 MCP（模型上下文协议），由 Anthropic 设计的开放协议，它如同 AI 领域的 USB 接口，旨在通过统一接口解决大模型连接不同数据源和工具的问题。文章详细介绍了 MCP 的架构、核心角色、工作原理以及如何与 Semantic Kernel 集成，为 .NET 开发者提供高效接入社区 MCP 服务器的方法，减少重复性平台对接工作。此外，还展示了 MCP 在操作浏览器、访问文件系统等场景中的应用效果，并探讨了其局限性及未来发展方向。在 AI 技术快速发展的背景下，MCP 的出现为实现 AI 模型的 “万物互联” 提供了可能，值得开发者关注与探索。
                
            </div>
            
            
            <div class="meta">
                
                <div class="date">
                    <i class="iconfont icon-calendar"></i>
                    <span>2025-03-09</span>
                </div>
                
                
                
                <div class="categories">
                    <i class="iconfont icon-folder"></i>
                    
                    <a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80">编程语言</a>
                    
                </div>
                
                
                
                
                <div class="tags">
                    <i class="iconfont icon-tag"></i>
                    
                    <a href="/tags/mcp">MCP</a>
                    
                    <a href="/tags/agent">Agent</a>
                    
                    <a href="/tags/semantic-kernel">Semantic Kernel</a>
                    
                    <a href="/tags/function-calling">Function Calling</a>
                    
                </div>
                
            </div>
        </div>
    </article>
    
    <article class="post-item s-card">
        
        
        
        <div class="content">
            
            <h2 class="title">
                <a href="/posts/face-photo-fast-classification-using-k-means-clustering/">基于 K-Means 聚类分析实现人脸照片的快速分类</a>
            </h2>
            
            
            <div class="summary">
                
                    本文介绍了使用 K-Means 聚类算法对人脸照片进行自动分类的方法，解决了 “脸盲症” 问题。通过 Dlib 提取人脸特征向量，并利用 Scikit-Learn 的 K-Means 聚类分析，能够快速将大量人脸照片按人物进行分类。文章详细讲解了 K-Means 算法的原理、K 值确定方法，以及如何使用 PCA 降维和 Matplotlib 可视化聚类结果。该技术方案帮助用户高效地整理和管理照片，避免了人工分类的繁琐过程。尽管 K-Means 算法简单高效，但其对簇数和初始中心的选择较为敏感，可能不适用于噪声数据和非凸形簇，建议在实际应用中结合 DBSCAN 等算法以提高聚类效果。
                
            </div>
            
            
            <div class="meta">
                
                <div class="date">
                    <i class="iconfont icon-calendar"></i>
                    <span>2025-01-14</span>
                </div>
                
                
                
                <div class="categories">
                    <i class="iconfont icon-folder"></i>
                    
                    <a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80">编程语言</a>
                    
                </div>
                
                
                
                
                <div class="tags">
                    <i class="iconfont icon-tag"></i>
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
                    
                    <a href="/tags/%E4%BA%BA%E8%84%B8%E5%88%86%E7%B1%BB">人脸分类</a>
                    
                    <a href="/tags/k-means">K-Means</a>
                    
                    <a href="/tags/scikit-learn">Scikit-Learn</a>
                    
                    <a href="/tags/%E8%81%9A%E7%B1%BB">聚类</a>
                    
                </div>
                
            </div>
        </div>
    </article>
    
</div> 
  </div>
  


<style>
.related-post {
  margin-top: 1rem;
}

.related-post .title {
  display: flex;
  flex-direction: row;
  align-items: center;
  justify-content: space-between;
  width: 100%;
  margin: 3rem 0 1rem 0;
  padding: 0 6px;
}

.related-post .title .name {
  display: flex;
  align-items: center;
  font-size: 24px;
  font-weight: bold;
}

.related-post .title .name .iconfont {
  font-size: 26px;
  font-weight: normal;
  margin-right: 8px;
}

.related-post .title .shuffle {
  opacity: 0.6;
  font-size: 14px;
  transition: color 0.3s, opacity 0.3s;
  cursor: pointer;
}

.related-post .title .shuffle:hover {
  opacity: 1;
  color: var(--main-color);
}
</style>


            
            <div id="comments">
                
<div id="main-comment" class="comment">
    <div v-if="!fill" class="title">
        <span class="name">
            <i class="iconfont icon-chat"></i>
            评论
        </span>
        <span class="tool"> 隐私政策 </span>
    </div>
    <link rel="stylesheet" href="https://unpkg.com/@waline/client@v3/dist/waline.css"/>
<div id="waline" class="waline-container"></div>
<style>
    .waline-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
    .waline-container .vcount {
        color: var(--card-text-color-main);
    }
</style>


    <script type="module">
        import { init } from 'https://unpkg.com/@waline/client@v3/dist/waline.js';
        init({
            el: '#waline',
            serverURL: 'https:\/\/waline.yuanpei.me\/',
            lang: 'zh',
            dark: 'auto',
            path: window.location.href,
            requiredMeta: ['nick','mail'],
            emoji: [
                '//unpkg.com/@waline/emojis@1.2.0/weibo'
            ],
            reaction: false,
        });
      </script>


</div>

            </div>
        </article>
        
        <aside class="main-aside"><div class="sticky"> 
<div class="aside-countdown s-card weidgets">
  <div class="card-title">
    <i class="fas fa-hourglass-half"></i>
    <span>倒计时</span>
  </div>
  <div class="card-content">
    
  </div>
</div> <div class="tags-cloud s-card weidgets">
  <div class="title">
    <i class="iconfont icon-hashtag"></i>
    <span class="title-name">热门标签</span>
  </div>
  <div class="all-tags">
    
  </div>
  <a href="/pages/tags" class="more-tags">查看全部</a>
</div><div class="site-data s-card weidgets">
    <div class="title">
      <i class="iconfont icon-chart"></i>
      <span class="title-name">站点数据</span>
    </div>
    <div class="all-data">
      <div class="data-item">
        <span class="name">
          <i class="iconfont icon-article"></i>
          文章总数
        </span>
        <span class="num">277 篇</span>
      </div>
      <div class="data-item">
        <span class="name">
          <i class="iconfont icon-date"></i>
          建站天数
        </span>
        <span class="num">200 天</span>
      </div>
      <div class="data-item">
        <span class="name">
          <i class="iconfont icon-visibility"></i>
          总访问量
        </span>
        <span class="num" id="busuanzi_value_site_pv">0</span>
      </div>
      <div class="data-item">
        <span class="name">
          <i class="iconfont icon-account"></i>
          总访客数
        </span>
        <span class="num" id="busuanzi_value_site_uv">0</span>
      </div>
    </div>
  </div></div>
  </aside>
  <style>
  .main-aside {
    padding-left: 1rem;
    display: flex;
    flex-direction: column;
    animation: fade-up 0.6s 0.3s backwards;
    .weidgets {
      padding: 18px;
      margin-bottom: 1rem;
      :deep(.title) {
        margin-bottom: 12px;
        font-weight: bold;
        display: flex;
        align-items: center;
        opacity: 0.75;
        .iconfont {
          opacity: 0.6;
          margin-right: 6px;
        }
        .title-name {
          opacity: 0.8;
        }
      }
    }
    .sticky {
      position: sticky;
      top: calc(60px + 1rem);
      .weidgets {
        animation: fade-up 0.6s 0.4s backwards;
        &:last-child {
          margin-bottom: 0;
        }
      }
    }
  }
  </style>
  
    </div>
</div>

        </main>

        <div class="footer-link">
    
    <div class="footer-bar">
      <span class="site-title">元视角</span>
      <span class="site-desc">纵有疾风起，人生不言弃</span>
      <a href="/" class="to-home">了解更多</a>
    </div>
    
  
    <div class="footer-social">
      
      <a href="https://github.com/yourusername" target="_blank" class="social-link">
        <i class="iconfont icon-github"></i>
      </a>
      
      <a href="https://twitter.com/yourusername" target="_blank" class="social-link">
        <i class="iconfont icon-weibo"></i>
      </a>
      
  
      <div class="logo" title="返回顶部" onclick="window.scrollTo({top: 0, behavior: 'smooth'})">
        <img src="/images/icons8-stellar-128.png" alt="author" class="author" />
      </div>
  
      
      <a href="mailto:qinyuanpei@163.com" target="_blank" class="social-link">
        <i class="iconfont icon-email"></i>
      </a>
      
      <a href="https://space.bilibili.com/yourid" target="_blank" class="social-link">
        <i class="iconfont icon-douban"></i>
      </a>
      
    </div>
  
    <div class="footer-sitemap">
      
      <div class="sitemap-item">
        <span class="title">博客</span>
        <div class="links">
          
          <a href="/posts"  class="link-text">
            近期文章
          </a>
          
          <a href="/categories"  class="link-text">
            全部分类
          </a>
          
          <a href="/tags"  class="link-text">
            全部标签
          </a>
          
          <a href="/archives"  class="link-text">
            文章归档
          </a>
          
        </div>
      </div>
      
      <div class="sitemap-item">
        <span class="title">项目</span>
        <div class="links">
          
          <a href="https://example1.com" target="_blank" class="link-text">
            项目1
          </a>
          
          <a href="https://example2.com" target="_blank" class="link-text">
            项目2
          </a>
          
          <a href="https://example2.com" target="_blank" class="link-text">
            项目3
          </a>
          
          <a href="https://example2.com" target="_blank" class="link-text">
            项目4
          </a>
          
        </div>
      </div>
      
      <div class="sitemap-item">
        <span class="title">专栏</span>
        <div class="links">
          
          <a href="https://blog.csdn.net/qinyuanpei/category_10852603.html" target="_blank" class="link-text">
            .NET 源代码探案系列
          </a>
          
          <a href="https://blog.csdn.net/qinyuanpei/category_7444699.html" target="_blank" class="link-text">
            Python 数据挖掘系列
          </a>
          
          <a href="https://blog.csdn.net/qinyuanpei/category_11484903.html" target="_blank" class="link-text">
            分布式丛林探险系列
          </a>
          
          <a href="https://blog.csdn.net/qinyuanpei/category_1708629.html" target="_blank" class="link-text">
            Unity3D 游戏开发系列
          </a>
          
        </div>
      </div>
      
      <div class="sitemap-item">
        <span class="title">页面</span>
        <div class="links">
          
          <a href="/guest"  class="link-text">
            畅所欲言
          </a>
          
          <a href="/books"  class="link-text">
            阅读记录
          </a>
          
          <a href="/movies"  class="link-text">
            观影记录
          </a>
          
          <a href="/musics"  class="link-text">
            听歌记录
          </a>
          
        </div>
      </div>
      
      <div class="sitemap-item">
        <span class="title">友情链接</span>
        <div class="links">
          
          <a href="https://blog.zhheo.com/"  class="link-text">
            张洪
          </a>
          
          <a href="https://blog.zhheo.com/"  class="link-text">
            张洪
          </a>
          
          <a href="https://blog.zhheo.com/"  class="link-text">
            张洪
          </a>
          
          <a href="https://blog.zhheo.com/"  class="link-text">
            更多
          </a>
          
        </div>
      </div>
      
    </div>
  </div><footer id="main-footer" class="main-footer">
    <div class="footer-content">
        <div class="footer-copyright">
            <span class="time" data-v-6001e979="">@ 2014 - 2025 By </span>
            <a href="https://www.imsyy.top" class="author link" target="_blank">
                飞鸿踏雪
            </a>
            
            
        </div>
        <div class="meta">
            <a class="power link" href="https://vitepress.dev/" target="_blank">
                <span class="by">Powered by</span>
                <span class="name">Hugo</span>
            </a>
            <a class="theme link" href="/pages/theme">
                <span class="name">主题</span>
            </a>
            <a class="rss link" href="https://blog.imsyy.top/rss.xml" target="_blank">
                <i class="iconfont icon-rss"></i>
                <span class="name" data-v-6001e979="">订阅</span>
            </a>
            <a class="cc link" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" target="_blank">
                <i class="iconfont icon-line"></i>
                <i class="iconfont icon-by-line"></i>
                <i class="iconfont icon-nc-line"></i><i
                    class="iconfont icon-nd-line"></i>
            </a>
        </div>
    </div>
</footer>

<script src="/js/search.min.f2af2dfa3be20e8e7e8c8989bab508289b71bf3730bc6e352738f2084973a1ab.js"></script>
<script>
    
    document.addEventListener('DOMContentLoaded', () => {
        Search.init();
    });
</script>


<script src="/js/theme.min.df71ca7373c5884a4022a354b524ddee31ff8069b6ff5151b5950296b2d3a7a8.js"></script>



<script src="/js/mobile-menu.min.a6c5ea25099e55c871ee73532ed859d8db9223b277b6f3eb13126a95df5cec60.js"></script><div class="modal search-modal" id="searchModal">
  <div class="modal-container">
    <div class="modal-header">
      <div class="modal-title">
        <i class="iconfont icon-search"></i>
        <span>全局搜索</span>
      </div>
      <div class="modal-close">
        <i class="iconfont icon-close"></i>
      </div>
    </div>

    <div class="search-container">
      <div class="search-box">
        <input 
          type="text" 
          id="searchInput"
          placeholder="想要搜点什么" 
          autocomplete="off"
          autofocus
        >
      </div>

      <div class="search-results" id="searchResults">
        <div class="no-result" id="noResult" style="display: none;">
          <i class="iconfont icon-search-empty"></i>
          <span class="text">搜索结果为空</span>
        </div>
        <div class="search-list" id="searchList"></div>
      </div>

      <div class="search-stats">
        <span class="text" id="searchStats"></span>
      </div>
    </div>
  </div>
</div>

<style>
.search-modal {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background-color: rgba(0, 0, 0, 0.5);
  z-index: 999;
  display: none;
}

.modal-container {
  position: relative;
  width: 90%;
  max-width: 768px;
  margin: 80px auto;
  background-color: var(--main-card-background);
  border-radius: 12px;
  padding: 1.5rem;
}

.modal-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
}

.modal-title {
  display: flex;
  align-items: center;
  font-size: 1.2rem;
  font-weight: bold;
}

.modal-title .iconfont {
  margin-right: 0.5rem;
}

.modal-close {
  cursor: pointer;
  padding: 0.5rem;
}

.search-box input {
  width: 100%;
  outline: none;
  border-radius: 8px;
  font-size: 16px;
  padding: 0.6rem 1rem;
  color: var(--main-font-color);
  font-family: var(--main-font-family);
  border: 1px solid var(--main-card-border);
  background-color: var(--main-card-second-background);
  transition: border-color 0.3s, box-shadow 0.3s;
}

.search-box input:focus {
  border-color: var(--main-color);
  box-shadow: 0 8px 16px -4px var(--main-color-bg);
}

.search-results {
  margin-top: 20px;
  min-height: 300px;
}

.no-result {
  height: 300px;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}

.no-result .iconfont {
  font-size: 40px;
  margin-bottom: 12px;
}

.no-result .text {
  font-size: 18px;
  opacity: 0.6;
}

.search-list .search-item {
  margin-bottom: 12px;
  padding: 1rem;
  border-radius: 8px;
  background-color: var(--main-card-second-background);
  cursor: pointer;
  transition: transform 0.3s;
}

.search-list .search-item:hover {
  transform: translateY(-2px);
}

.search-item .title {
  font-size: 16px;
  margin-bottom: 6px;
}

.search-item .content {
  color: var(--main-font-second-color);
  font-size: 14px;
  margin-top: 8px;
}

.search-stats {
  margin-top: 1rem;
  font-size: 14px;
  color: var(--main-font-second-color);
}

.highlight {
  color: var(--main-color);
  background: transparent;
}
</style> 
    </body>
</html> 